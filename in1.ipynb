{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Kl_RwJR7McGXc9CwrhdtcELo3i7pjH-k",
      "authorship_tag": "ABX9TyM/rDkw4xho6Uyh96gRzQY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slifer4195/bertTransfer/blob/main/in1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh8QfBTHkk3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da142a89-8f40-43ee-ddb7-3ded5f8c400c"
      },
      "source": [
        "pip install ktrain\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.6/dist-packages (0.25.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.9)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.5)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: transformers<4.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.5.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.8)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.1.95)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.86.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ktrain) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (0.9.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.12.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->ktrain) (2.1.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.19->ktrain) (2.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->ktrain) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (53.0.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.86.0->ktrain) (0.38.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.0,>=3.1.0->ktrain) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (2.10.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.14.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.6.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.27.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert>=0.86.0->ktrain) (0.46.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2ObogdkaCR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "e30401a1-08e5-4f93-ac99-7de4791627e7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "import os\r\n",
        "import ktrain\r\n",
        "from ktrain import text\r\n",
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "import re\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from collections import Counter\r\n",
        "import csv\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "\r\n",
        "labels = []           #labels\r\n",
        "title = []          #title\r\n",
        "\r\n",
        "#reading training sample but must downsample\r\n",
        "cnt = 0\r\n",
        "with open(\"train.csv\", \"r\", encoding='utf-8') as csv_file:\r\n",
        "    csv_reader = csv.reader(csv_file)\r\n",
        "    print(\"reading csv file......\")\r\n",
        "    print(\"Please wait for a while as the csv file is very long.\")\r\n",
        "    for line in csv_reader:\r\n",
        "        labels.append(int(line[0]))\r\n",
        "        title.append(line[1] + ' '+ line[2]+ ' '+line[3])\r\n",
        "        cnt += 1\r\n",
        "        if cnt == 10000: break;\r\n",
        "\r\n",
        "#this is to read all the classfications for labels\r\n",
        "classes =[]\r\n",
        "with open(\"classes.txt\", \"r\", encoding='utf-8') as txt:\r\n",
        "    print(\"reading classes.txt\")\r\n",
        "    for line in txt:\r\n",
        "        classes.append(line)\r\n",
        "\r\n",
        "#this function remove urls\r\n",
        "def removing_URL(text):\r\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\r\n",
        "    return url.sub(r\"\", text)\r\n",
        "\r\n",
        "#remove punct\r\n",
        "def removing_punct(text):\r\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\r\n",
        "    return text.translate(translator)\r\n",
        "\r\n",
        "stop = set(stopwords.words('english'))\r\n",
        "def removing_stopewords(text):\r\n",
        "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\r\n",
        "    return \" \".join(filtered_words)\r\n",
        "\r\n",
        "title = list(map(removing_URL, title))\r\n",
        "title = list(map(removing_punct, title))\r\n",
        "title = list(map(removing_stopewords, title))\r\n",
        "\r\n",
        "\r\n",
        "val_x = []           #labels\r\n",
        "val_Y = []          #title\r\n",
        "\r\n",
        "#reading training sample but must downsample\r\n",
        "cnt = 0\r\n",
        "with open(\"test.csv\", \"r\", encoding='utf-8') as csv_file:\r\n",
        "    csv_reader = csv.reader(csv_file)\r\n",
        "    print(\"reading csv test file......\")\r\n",
        "    print(\"Please wait for a while as the csv file is very long.\")\r\n",
        "    for line in csv_reader:\r\n",
        "        val_Y.append(int(line[0]))\r\n",
        "        val_x.append(line[1] + ' '+ line[2]+ ' '+line[3])\r\n",
        "        cnt += 1\r\n",
        "        if cnt == 2000: break;\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Count unique words kinda like diction\r\n",
        "def counter_word(text_col):\r\n",
        "    count = Counter()\r\n",
        "    for text in text_col:\r\n",
        "        for word in text.split():\r\n",
        "            count[word] += 1\r\n",
        "    return count\r\n",
        "\r\n",
        "counter = counter_word(title)\r\n",
        "\r\n",
        "train_size = int(len(title) * 0.8)\r\n",
        "\r\n",
        "train_df = title[:train_size]  #70percent valid\r\n",
        "val_df = title[train_size:]    #30percent valid\r\n",
        "trainLabel_df = labels[:train_size]  #70percent valid\r\n",
        "valLabel_df = labels[train_size:]   #30percent valid\r\n",
        "\r\n",
        "#you can use val_df, valLabel-df\r\n",
        "#val_x and val_y are the data from test.csv\r\n",
        "train_y = []\r\n",
        "val_y = []\r\n",
        "\r\n",
        "for i in range(len(trainLabel_df)):\r\n",
        "  train_y.append(classes[trainLabel_df[i]-1])\r\n",
        "\r\n",
        "for i in range(len(val_Y)):\r\n",
        "  val_y.append(classes[val_Y[i] - 1])\r\n",
        "\r\n",
        "classy = [0,1,2,3,4,5,6,7,8,9]\r\n",
        "model_name = 'distilbert-base-uncased'\r\n",
        "trans = text.Transformer(model_name,maxlen=512, class_names = classy)\r\n",
        "train_data = trans.preprocess_train(train_df, train_y)\r\n",
        "test_data = trans.preprocess_test(val_x, val_y)\r\n",
        "\r\n",
        "\r\n",
        "#using pretrained network distilbert\r\n",
        "\r\n",
        "model = trans.get_classifier()\r\n",
        "\r\n",
        "learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data,batch_size = 16)\r\n",
        "\r\n",
        "learner.fit_onecycle(1e-4, 3)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "reading classes.txt\n",
            "reading csv test file......\n",
            "Please wait for a while as the csv file is very long.\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 43\n",
            "\t95percentile : 129\n",
            "\t99percentile : 281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ktrain/utils.py:589: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n",
            "  if self.get_classes(): warnings.warn('class_names argument was ignored, as they were extracted from string labels in dataset')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 81\n",
            "\t95percentile : 244\n",
            "\t99percentile : 506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 0.0001...\n",
            "Epoch 1/3\n",
            "500/500 [==============================] - 676s 1s/step - loss: 1.7471 - accuracy: 0.4303 - val_loss: 1.0005 - val_accuracy: 0.6769\n",
            "Epoch 2/3\n",
            "500/500 [==============================] - 669s 1s/step - loss: 0.9738 - accuracy: 0.6892 - val_loss: 0.8117 - val_accuracy: 0.7418\n",
            "Epoch 3/3\n",
            "500/500 [==============================] - 669s 1s/step - loss: 0.6054 - accuracy: 0.8123 - val_loss: 0.6360 - val_accuracy: 0.8007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba683c8e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}